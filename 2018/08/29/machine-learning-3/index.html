<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Machine Learning(ML) - 손실 줄이기 | GNIDOC의 블로그</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="본 게시물은 구글 머신러닝 단기집중과정 스터디을 참고하여 작성되었습니다.   손실 줄이기(Reducing Loss) 반복학습(Iterative learning) 머신러닝 알고리즘 매개변수 업데이트 계산? 경사하강법(Gradient Descent) 학습률(Learning Rate) 확률적 경사하강법(Stochastic Gradient Descent)">
<meta name="keywords" content="머신러닝 단기집중과정">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning(ML) - 손실 줄이기">
<meta property="og:url" content="https://gnidoc327.github.io/2018/08/29/machine-learning-3/index.html">
<meta property="og:site_name" content="GNIDOC의 블로그">
<meta property="og:description" content="본 게시물은 구글 머신러닝 단기집중과정 스터디을 참고하여 작성되었습니다.   손실 줄이기(Reducing Loss) 반복학습(Iterative learning) 머신러닝 알고리즘 매개변수 업데이트 계산? 경사하강법(Gradient Descent) 학습률(Learning Rate) 확률적 경사하강법(Stochastic Gradient Descent)">
<meta property="og:locale" content="ko">
<meta property="og:image" content="https://gnidoc327.github.io/2018/08/27/machine-learning-2/figure2.JPG">
<meta property="og:image" content="https://gnidoc327.github.io/2018/08/29/machine-learning-3/figure1.JPG">
<meta property="og:image" content="https://gnidoc327.github.io/2018/08/29/machine-learning-3/figure2.JPG">
<meta property="og:image" content="https://gnidoc327.github.io/2018/08/29/machine-learning-3/figure3.JPG">
<meta property="og:image" content="https://gnidoc327.github.io/2018/08/29/machine-learning-3/figure4.JPG">
<meta property="og:image" content="https://gnidoc327.github.io/2018/08/29/machine-learning-3/figure5.JPG">
<meta property="og:updated_time" content="2018-08-29T11:19:05.330Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine Learning(ML) - 손실 줄이기">
<meta name="twitter:description" content="본 게시물은 구글 머신러닝 단기집중과정 스터디을 참고하여 작성되었습니다.   손실 줄이기(Reducing Loss) 반복학습(Iterative learning) 머신러닝 알고리즘 매개변수 업데이트 계산? 경사하강법(Gradient Descent) 학습률(Learning Rate) 확률적 경사하강법(Stochastic Gradient Descent)">
<meta name="twitter:image" content="https://gnidoc327.github.io/2018/08/27/machine-learning-2/figure2.JPG">
  
    <link rel="alternate" href="/atom.xml" title="GNIDOC의 블로그" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  <script async src = "https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script >
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">GNIDOC의 블로그</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">삽질 컬렉션</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="검색"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://gnidoc327.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-machine-learning-3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/29/machine-learning-3/" class="article-date">
  <time datetime="2018-08-29T07:06:06.000Z" itemprop="datePublished">2018-08-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/머신러닝-단기집중과정/">머신러닝 단기집중과정</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Machine Learning(ML) - 손실 줄이기
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>본 게시물은 <a href="[https://developers.google.com/machine-learning/crash-course/?utm_source=DevRel&utm_medium=StudyJam&utm_campaign=q1y2018&utm_term=&utm_content=mlcc]" title="[구글 머신러닝 단기집중과정 스터디]">구글 머신러닝 단기집중과정 스터디</a>을 참고하여 작성되었습니다.</p>
<!-- toc -->
<ul>
<li><a href="#손실-줄이기reducing-loss">손실 줄이기(Reducing Loss)</a><ul>
<li><a href="#반복학습iterative-learning">반복학습(Iterative learning)</a></li>
<li><a href="#머신러닝-알고리즘">머신러닝 알고리즘</a></li>
<li><a href="#매개변수-업데이트-계산">매개변수 업데이트 계산?</a></li>
<li><a href="#경사하강법gradient-descent">경사하강법(Gradient Descent)</a></li>
<li><a href="#학습률learning-rate">학습률(Learning Rate)</a></li>
<li><a href="#확률적-경사하강법stochastic-gradient-descent">확률적 경사하강법(Stochastic Gradient Descent)</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<h2><span id="손실-줄이기reducing-loss">손실 줄이기(Reducing Loss)</span></h2><p>  앞에서 배운 모델의 방정식이 있다.</p>
<p>  <img src="/2018/08/27/machine-learning-2/figure2.JPG" alt="모델의 방정식"> </p>
<p>  하지만 단순히 직선으로 이뤄져있기 때문에 위의 방정식으로는 각 데이터마다 차이가 크다.<br>  예를 들어, 귀뚜라미가 150번 울때의 온도는 방정식과 거의 동일하지만 130번 울때의 온도는 약 5도로 차이가 크다.</p>
<p>  따라서 머신러닝은, 모델의 방정식을 최대한 입력된 데이터(학습데이터)와 가깝게(손실율이 적게) 만드는 것이 목표이다.</p>
<h3><span id="반복학습iterative-learning">반복학습(Iterative learning)</span></h3><ul>
<li>핫 앤 콜드(Hot &amp; Cold)<ul>
<li>술래가 눈을 감은 상태에서 임의로 정한 물건과 술래가 가까우면 핫(Hot), 멀어지면 콜드(Cold)를 외치는 게임</li>
<li>머신러닝도 동일하게 w₁의 값을 계속 바꿔가며(Hot &amp; Cold) 가장 손실율이 적은 모델(임의로 정한 물건)을 찾는 것이다.<br><img src="/2018/08/29/machine-learning-3/figure1.JPG" width="400" height="400" alt="Figure 1 : 반복 방식의 모델 학습"></li>
</ul>
</li>
</ul>
<h3><span id="머신러닝-알고리즘">머신러닝 알고리즘</span></h3><p>  머신러닝 알고리즘으로 모델을 학습하는데 사용하는 반복적인 시행착오 과정<br>  하나 이상의 특성을 입력하여 하나의 예측을 출력함</p>
<ul>
<li><p>모델(예측 함수)<br>하나의 특성으로 하나의 예측을 반환하는 모델</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y&apos; = b + w₁x₁</span><br></pre></td></tr></table></figure>
<ul>
<li>x₁ = 10, b = 0, w₁ = 0 이면  y’ = 0 + 0(10) = 0 </li>
<li>x₁이 10일때 올바른 라벨(출력값=y)이 10이라면? -&gt; 손실 발생!<ul>
<li>그럼 손실 계산은 어떻게 할까?</li>
</ul>
</li>
</ul>
</li>
<li><p>손실 계산(Compute Loss)</p>
<ul>
<li>Figure 1에서 손실 계산에서 사용되는게 손실 함수</li>
<li>손실 함수는 두개의 입력 값을 가짐<ul>
<li>y’: 특성 x에 대한 모델의 예측값(학습을 통해서 만든 모델의 결과 값)</li>
<li>y : 특성 x에 대한 올바른 라벨(실제 데이터 값)</li>
</ul>
</li>
</ul>
</li>
<li><p>매개변수 업데이트 계산(compute parameter updates)</p>
<ul>
<li>모델, 손실 계산을 통해서 매개변수인 b와 w₁의 값을 변경</li>
</ul>
</li>
<li><p>다시 처음부터 반복 </p>
<ul>
<li>가장 손실 값이 낮은 모델의 매개변수를 찾을때까지 반복함</li>
<li>전체 손실이 변하지 않거나 매우 느리게 변한다면? 모델이 수렴(converged)했다고 한다</li>
</ul>
</li>
</ul>
<h3><span id="매개변수-업데이트-계산">매개변수 업데이트 계산?</span></h3><p>  손실 계산은 y, y’ 두개의 입력값으로 손실 함수를 만들어서 계산한다고 하는데<br>  매개변수 업데이트 계산은 뭘로 한다는 걸까?<br>  w₁와 b 값을 업데이트 한다는건데 뭘까?</p>
<ul>
<li>대충 이런 것이다.(일단 w₁만으로 설명)<ul>
<li>w₁값을 업데이트한다.(매개변수 업데이트)</li>
<li>w₁을 업데이트할때마다 손실 계산을 함</li>
<li>그럼 아래와 같은 형식의 그래프가 나옴<br><img src="/2018/08/29/machine-learning-3/figure2.JPG" width="400" height="400" alt="Figure 2 : 볼록 함수 모양의 그래프"></li>
<li>그렇다면 최소값인 지점은? 기울기가 정확하게 0인 지점(손실 함수가 수렴하는 지점)</li>
<li>문제는 모든 w₁ 값의 손실 계산을 하는건 비효율적인 방법<ul>
<li>만약 w₁가 실수 전체 범위라면 0~1 사이에 값만 넣어도 무한대의 시도가 필요함</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3><span id="경사하강법gradient-descent">경사하강법(Gradient Descent)</span></h3><ul>
<li>모든 w₁ 값을 계산하는 것은 비효율적이므로 임의의 값을 시작으로 일정 간격으로 손실 그래프의 기울기를 계산!(=편미분)<ul>
<li>미분(Derivatives)<ul>
<li>해당하는 점의 기울기를 구한 값</li>
<li>ex) x=2일때 기울기</li>
</ul>
</li>
<li>편미분(Partial derivatives)<br><img src="/2018/08/29/machine-learning-3/figure3.JPG" width="400" height="400" alt="Figure 3 : 편미분"><ul>
<li>특정 구간의 기울기를 구한 값</li>
<li>ex) x=2~4 구간의 기울기</li>
</ul>
</li>
</ul>
</li>
<li>모든 값을 계산할 필요없이 적절한 간격을 설정하여 구하면 됨</li>
<li>여기서 말하는 간격이 <strong>학습률</strong>을 뜻함! </li>
<li>경사하강법에서는 음의 기울기를 사용(↘방향)<ul>
<li>즉, 가중치가 증가할때 손실은 줄어들어야함</li>
<li>따라서 기울기도 벡터(방향과 크기를 가짐)</li>
</ul>
</li>
<li>다음 지점을 결정하는법 = 기울기 X 학습률 or 보폭(스칼라)</li>
</ul>
<h3><span id="학습률learning-rate">학습률(Learning Rate)</span></h3><ul>
<li>초매개변수(Hyperparameters) : 프로그래머가 머신러닝 알고리즘에서 조정하는 값</li>
<li>학습률이 너무 작으면 학습 시간이 오래 걸림<br><img src="/2018/08/29/machine-learning-3/figure4.JPG" width="400" height="400" alt="Figure 4 : 학습률이 너무 작아 오래 걸림"></li>
<li>반대로 너무 크면 곡선의 최저점을 이탈함<br><img src="/2018/08/29/machine-learning-3/figure5.JPG" width="400" height="400" alt="Figure 5 : 학습률이 너무 커 최저점을 이탈"></li>
<li><a href="https://ko.wikipedia.org/wiki/%EA%B3%A8%EB%94%94%EB%9D%BD%EC%8A%A4_%EC%9B%90%EB%A6%AC" target="_blank" rel="noopener">골디락스 학습률</a>
<ul>
<li>효율적으로 결과를 얻을 수 있는 학습률</li>
<li>실버 불릿같은 존재(알면 한번에 그렇게 했겠지…)</li>
</ul>
</li>
</ul>
<h3><span id="확률적-경사하강법stochastic-gradient-descent">확률적 경사하강법(Stochastic Gradient Descent)</span></h3><ul>
<li>데이터 세트가 엄청나게 많거나 특성이 많은 경우, 전체 데이터를 경사하강법을 통해서 학습하면 오래걸림</li>
<li>따라서 무작위로 일부 데이터를 뽑아서 학습시킴</li>
<li>데이터는 적어지기 때문에 노이즈(오차)가 발생할 수 있음</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gnidoc327.github.io/2018/08/29/machine-learning-3/" data-id="cjlev1seo000038vfv386fc00" class="article-share-link">공유</a>
      
        <a href="https://gnidoc327.github.io/2018/08/29/machine-learning-3/#disqus_thread" class="article-comment-link">댓글</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/머신러닝-단기집중과정/">머신러닝 단기집중과정</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2018/08/27/machine-learning-2/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">이전</strong>
      <div class="article-nav-title">Machine Learning(ML) - ML로 전환하기</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread"></div>
  <script>

    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
      var d = document, s = d.createElement('script');
      s.src = 'https://gnidoc327-blog.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">카테고리</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/etc/">etc</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/머신러닝-단기집중과정/">머신러닝 단기집중과정</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">태그</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/django/">django</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/fascrap/">fascrap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/node/">node</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/머신러닝-단기집중과정/">머신러닝 단기집중과정</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">태그 클라우드</h3>
    <div class="widget tagcloud">
      <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/fascrap/" style="font-size: 10px;">fascrap</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/node/" style="font-size: 10px;">node</a> <a href="/tags/머신러닝-단기집중과정/" style="font-size: 20px;">머신러닝 단기집중과정</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">아카이브</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">8월 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">4월 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">최근 포스트</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/08/29/machine-learning-3/">Machine Learning(ML) - 손실 줄이기</a>
          </li>
        
          <li>
            <a href="/2018/08/27/machine-learning-2/">Machine Learning(ML) - ML로 전환하기</a>
          </li>
        
          <li>
            <a href="/2018/08/20/machine-learning-1/">Machine Learning(ML) - ML 문제로 표현하기(용어 정리)</a>
          </li>
        
          <li>
            <a href="/2018/08/15/new-django-project/">새로운 장고 프로젝트</a>
          </li>
        
          <li>
            <a href="/2018/08/11/machine-learning-week-0/">Machine Learning(ML) 첫걸음</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 gnidoc327<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
    <div id="footer-count">
      <div id="view-count">
        조회수 : <span id="busuanzi_value_site_pv"></span>
      </div>
      <div id="visitor-count">
        총 방문자 : <span id="busuanzi_value_site_uv"></span>
      </div>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    
<script>
  var disqus_shortname = 'https-gnidoc327-github-io';
  
  var disqus_url = 'https://gnidoc327.github.io/2018/08/29/machine-learning-3/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>