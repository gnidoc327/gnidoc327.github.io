<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>GNIDOC의 블로그</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="GNIDOC의 블로그">
<meta property="og:url" content="https://gnidoc327.github.io/index.html">
<meta property="og:site_name" content="GNIDOC의 블로그">
<meta property="og:locale" content="ko">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="GNIDOC의 블로그">
  <meta http-equiv="refresh" content="0; url=https://gnidoc.tistory.com/">
<link rel="canonical" href="https://gnidoc.tistory.com/">
  
    <link rel="alternate" href="/atom.xml" title="GNIDOC의 블로그" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  <script async src = "https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script >
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">GNIDOC의 블로그</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">삽질 컬렉션</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="검색"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://gnidoc327.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-machine-learning-3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/29/machine-learning-3/" class="article-date">
  <time datetime="2018-08-29T07:06:06.000Z" itemprop="datePublished">2018-08-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/머신러닝-단기집중과정/">머신러닝 단기집중과정</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/29/machine-learning-3/">Machine Learning(ML) - 손실 줄이기</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>본 게시물은 <a href="[https://developers.google.com/machine-learning/crash-course/?utm_source=DevRel&utm_medium=StudyJam&utm_campaign=q1y2018&utm_term=&utm_content=mlcc]" title="[구글 머신러닝 단기집중과정 스터디]">구글 머신러닝 단기집중과정 스터디</a>을 참고하여 작성되었습니다.</p>
<!-- toc -->
<ul>
<li><a href="#손실-줄이기reducing-loss">손실 줄이기(Reducing Loss)</a><ul>
<li><a href="#반복학습iterative-learning">반복학습(Iterative learning)</a></li>
<li><a href="#머신러닝-알고리즘">머신러닝 알고리즘</a></li>
<li><a href="#매개변수-업데이트-계산">매개변수 업데이트 계산?</a></li>
<li><a href="#경사하강법gradient-descent">경사하강법(Gradient Descent)</a></li>
<li><a href="#학습률learning-rate">학습률(Learning Rate)</a></li>
<li><a href="#확률적-경사하강법stochastic-gradient-descent">확률적 경사하강법(Stochastic Gradient Descent)</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<h2><span id="손실-줄이기reducing-loss">손실 줄이기(Reducing Loss)</span></h2><p>  앞에서 배운 모델의 방정식이 있다.</p>
<p>  <img src="/2018/08/27/machine-learning-2/figure2.JPG" alt="모델의 방정식"> </p>
<p>  하지만 단순히 직선으로 이뤄져있기 때문에 위의 방정식으로는 각 데이터마다 차이가 크다.<br>  예를 들어, 귀뚜라미가 150번 울때의 온도는 방정식과 거의 동일하지만 130번 울때의 온도는 약 5도로 차이가 크다.</p>
<p>  따라서 머신러닝은, 모델의 방정식을 최대한 입력된 데이터(학습데이터)와 가깝게(손실율이 적게) 만드는 것이 목표이다.</p>
<h3><span id="반복학습iterative-learning">반복학습(Iterative learning)</span></h3><ul>
<li>핫 앤 콜드(Hot &amp; Cold)<ul>
<li>술래가 눈을 감은 상태에서 임의로 정한 물건과 술래가 가까우면 핫(Hot), 멀어지면 콜드(Cold)를 외치는 게임</li>
<li>머신러닝도 동일하게 w₁의 값을 계속 바꿔가며(Hot &amp; Cold) 가장 손실율이 적은 모델(임의로 정한 물건)을 찾는 것이다.<br><img src="/2018/08/29/machine-learning-3/figure1.JPG" width="400" height="400" alt="Figure 1 : 반복 방식의 모델 학습"></li>
</ul>
</li>
</ul>
<h3><span id="머신러닝-알고리즘">머신러닝 알고리즘</span></h3><p>  머신러닝 알고리즘으로 모델을 학습하는데 사용하는 반복적인 시행착오 과정<br>  하나 이상의 특성을 입력하여 하나의 예측을 출력함</p>
<ul>
<li><p>모델(예측 함수)<br>하나의 특성으로 하나의 예측을 반환하는 모델</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y&apos; = b + w₁x₁</span><br></pre></td></tr></table></figure>
<ul>
<li>x₁ = 10, b = 0, w₁ = 0 이면  y’ = 0 + 0(10) = 0 </li>
<li>x₁이 10일때 올바른 라벨(출력값=y)이 10이라면? -&gt; 손실 발생!<ul>
<li>그럼 손실 계산은 어떻게 할까?</li>
</ul>
</li>
</ul>
</li>
<li><p>손실 계산(Compute Loss)</p>
<ul>
<li>Figure 1에서 손실 계산에서 사용되는게 손실 함수</li>
<li>손실 함수는 두개의 입력 값을 가짐<ul>
<li>y’: 특성 x에 대한 모델의 예측값(학습을 통해서 만든 모델의 결과 값)</li>
<li>y : 특성 x에 대한 올바른 라벨(실제 데이터 값)</li>
</ul>
</li>
</ul>
</li>
<li><p>매개변수 업데이트 계산(compute parameter updates)</p>
<ul>
<li>모델, 손실 계산을 통해서 매개변수인 b와 w₁의 값을 변경</li>
</ul>
</li>
<li><p>다시 처음부터 반복 </p>
<ul>
<li>가장 손실 값이 낮은 모델의 매개변수를 찾을때까지 반복함</li>
<li>전체 손실이 변하지 않거나 매우 느리게 변한다면? 모델이 수렴(converged)했다고 한다</li>
</ul>
</li>
</ul>
<h3><span id="매개변수-업데이트-계산">매개변수 업데이트 계산?</span></h3><p>  손실 계산은 y, y’ 두개의 입력값으로 손실 함수를 만들어서 계산한다고 하는데<br>  매개변수 업데이트 계산은 뭘로 한다는 걸까?<br>  w₁와 b 값을 업데이트 한다는건데 뭘까?</p>
<ul>
<li>대충 이런 것이다.(일단 w₁만으로 설명)<ul>
<li>w₁값을 업데이트한다.(매개변수 업데이트)</li>
<li>w₁을 업데이트할때마다 손실 계산을 함</li>
<li>그럼 아래와 같은 형식의 그래프가 나옴<br><img src="/2018/08/29/machine-learning-3/figure2.JPG" width="400" height="400" alt="Figure 2 : 볼록 함수 모양의 그래프"></li>
<li>그렇다면 최소값인 지점은? 기울기가 정확하게 0인 지점(손실 함수가 수렴하는 지점)</li>
<li>문제는 모든 w₁ 값의 손실 계산을 하는건 비효율적인 방법<ul>
<li>만약 w₁가 실수 전체 범위라면 0~1 사이에 값만 넣어도 무한대의 시도가 필요함</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3><span id="경사하강법gradient-descent">경사하강법(Gradient Descent)</span></h3><ul>
<li>모든 w₁ 값을 계산하는 것은 비효율적이므로 임의의 값을 시작으로 일정 간격으로 손실 그래프의 기울기를 계산!(=편미분)<ul>
<li>미분(Derivatives)<ul>
<li>해당하는 점의 기울기를 구한 값</li>
<li>ex) x=2일때 기울기</li>
</ul>
</li>
<li>편미분(Partial derivatives)<br><img src="/2018/08/29/machine-learning-3/figure3.JPG" width="400" height="400" alt="Figure 3 : 편미분"><ul>
<li>특정 구간의 기울기를 구한 값</li>
<li>ex) x=2~4 구간의 기울기</li>
</ul>
</li>
</ul>
</li>
<li>모든 값을 계산할 필요없이 적절한 간격을 설정하여 구하면 됨</li>
<li>여기서 말하는 간격이 <strong>학습률</strong>을 뜻함! </li>
<li>경사하강법에서는 음의 기울기를 사용(↘방향)<ul>
<li>즉, 가중치가 증가할때 손실은 줄어들어야함</li>
<li>따라서 기울기도 벡터(방향과 크기를 가짐)</li>
</ul>
</li>
<li>다음 지점을 결정하는법 = 기울기 X 학습률 or 보폭(스칼라)</li>
</ul>
<h3><span id="학습률learning-rate">학습률(Learning Rate)</span></h3><ul>
<li>초매개변수(Hyperparameters) : 프로그래머가 머신러닝 알고리즘에서 조정하는 값</li>
<li>학습률이 너무 작으면 학습 시간이 오래 걸림<br><img src="/2018/08/29/machine-learning-3/figure4.JPG" width="400" height="400" alt="Figure 4 : 학습률이 너무 작아 오래 걸림"></li>
<li>반대로 너무 크면 곡선의 최저점을 이탈함<br><img src="/2018/08/29/machine-learning-3/figure5.JPG" width="400" height="400" alt="Figure 5 : 학습률이 너무 커 최저점을 이탈"></li>
<li><a href="https://ko.wikipedia.org/wiki/%EA%B3%A8%EB%94%94%EB%9D%BD%EC%8A%A4_%EC%9B%90%EB%A6%AC" target="_blank" rel="noopener">골디락스 학습률</a>
<ul>
<li>효율적으로 결과를 얻을 수 있는 학습률</li>
<li>실버 불릿같은 존재(알면 한번에 그렇게 했겠지…)</li>
</ul>
</li>
</ul>
<h3><span id="확률적-경사하강법stochastic-gradient-descent">확률적 경사하강법(Stochastic Gradient Descent)</span></h3><ul>
<li>데이터 세트가 엄청나게 많거나 특성이 많은 경우, 전체 데이터를 경사하강법을 통해서 학습하면 오래걸림</li>
<li>따라서 무작위로 일부 데이터를 뽑아서 학습시킴</li>
<li>데이터는 적어지기 때문에 노이즈(오차)가 발생할 수 있음</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gnidoc327.github.io/2018/08/29/machine-learning-3/" data-id="cjlev1seo000038vfv386fc00" class="article-share-link">공유</a>
      
        <a href="https://gnidoc327.github.io/2018/08/29/machine-learning-3/#disqus_thread" class="article-comment-link">댓글</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/머신러닝-단기집중과정/">머신러닝 단기집중과정</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-machine-learning-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/27/machine-learning-2/" class="article-date">
  <time datetime="2018-08-27T08:20:56.000Z" itemprop="datePublished">2018-08-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/머신러닝-단기집중과정/">머신러닝 단기집중과정</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/27/machine-learning-2/">Machine Learning(ML) - ML로 전환하기</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>본 게시물은 <a href="[https://developers.google.com/machine-learning/crash-course/?utm_source=DevRel&utm_medium=StudyJam&utm_campaign=q1y2018&utm_term=&utm_content=mlcc]" title="[구글 머신러닝 단기집중과정 스터디]">구글 머신러닝 단기집중과정 스터디</a>을 참고하여 작성되었습니다.</p>
<!-- toc -->
<ul>
<li><a href="#ml로-전환하기">ML로 전환하기</a><ul>
<li><a href="#선형-회귀">선형 회귀</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<h2><span id="ml로-전환하기">ML로 전환하기</span></h2><ul>
<li>ML로 전환하기? <ul>
<li>주어진 데이터를 통해서 선형 모델을 만들라는 것(=선형회귀!)</li>
<li>어떤 문제를 회귀화 기본적인 Flow(흐름)을 파악하자 - Step by Step!</li>
</ul>
</li>
</ul>
<h3><span id="선형-회귀">선형 회귀</span></h3><ul>
<li>제일 먼저, 데이터를 그래프로 만들어 검토해야한다</li>
<li>왜냐? 데이터가 잘못되면 우리가 원하는 모델을 얻을 수 없기 때문!</li>
<li>예시) 온도별 1분당 귀뚜라미가 우는 횟수 <ul>
<li>나는 귀뚜라미가 몇번 우는지를 통해서 온도를 알고 싶다!</li>
<li>데이터를 먼저 좌표로 나타낸다<br><img src="/2018/08/27/machine-learning-2/figure1.JPG" width="400" height="400" alt="Figure 1 : 귀뚜라미가 온도에 따라 1분당 우는 횟수"><br>데이터간의 관계를 보면 온도와 1분당 우는 횟수는 서로 비례하는 관계를 가짐<br>따라서, 이 관계를 근사치로 표현할 수 있는 단 하나의 직선을 만들어 낼 수 있음</li>
<li>두번째 데이터간의 관계를 근사치로 표현한 직선<br><img src="/2018/08/27/machine-learning-2/figure2.JPG" width="400" height="400" alt="Figure 2 : 근사치 그래프(선형 관계)"><br>근사치로 표현한 직선이 모든 점(데이터)를 통과하지 않지만 대략적인 관계를 보여줌<br>이 그래프(관계)는 어떤 공식(모델의 방정식)으로 나타낼 수 있다 </li>
<li>직선의 방정식<br><img src="/2018/08/27/machine-learning-2/figure3.JPG" width="200" height="200" alt="Figure 3 : 직선의 방정식"><br>위에서 만든 직선을 수학적으로 공식화한 것<ul>
<li>y : 온도, 예측하려는 값(우리가 알고 싶은 값)</li>
<li>m : 선의 기울기</li>
<li>x : 1분당 우는 횟수, 입력 특성 값(귀뚜라미가 1분에 100번 울었을때 온도를 알고 싶다면? x=100을 입력)</li>
<li>b : y절편(직선이 y축과 만나는 점)</li>
</ul>
</li>
<li>모델의 방정식<br><img src="/2018/08/27/machine-learning-2/figure4.JPG" width="200" height="200" alt="Figure 4 : 모델의 방정식"><br>위에서 구한 직선의 방정식을 머신러닝의 관습에 맞게 작성한 방정식<ul>
<li>y’ : 예측된 라벨(얻고자 하는 출력)</li>
<li>w₁ : 특성1의 가중치. 가중치는 기울기와 같은 개념</li>
<li>x₁ : 특성1(알려진 입력)</li>
<li>b : 편향(y절편). w_0\이라고도 표현함</li>
</ul>
</li>
<li>정교한 모델(여러 특성에 의존하는 모델)<br><img src="/2018/08/27/machine-learning-2/figure5.JPG" width="200" height="200" alt="Figure 5 : 3가지 특성에 의존하는 모델의 방정식"><br>만약에 귀뚜라미가 우는 시간/횟수, 나이 3가지 특성에 영향을 받는 경우에는 위와 같은 방정식이 나옴</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://gnidoc327.github.io/2018/08/27/machine-learning-2/" data-id="cjlet232g000ahgvfi05wb205" class="article-share-link">공유</a>
      
        <a href="https://gnidoc327.github.io/2018/08/27/machine-learning-2/#disqus_thread" class="article-comment-link">댓글</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/머신러닝-단기집중과정/">머신러닝 단기집중과정</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">다음 &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">카테고리</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/etc/">etc</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/머신러닝-단기집중과정/">머신러닝 단기집중과정</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">태그</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/django/">django</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/fascrap/">fascrap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/node/">node</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/머신러닝-단기집중과정/">머신러닝 단기집중과정</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">태그 클라우드</h3>
    <div class="widget tagcloud">
      <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/fascrap/" style="font-size: 10px;">fascrap</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/node/" style="font-size: 10px;">node</a> <a href="/tags/머신러닝-단기집중과정/" style="font-size: 20px;">머신러닝 단기집중과정</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">아카이브</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">8월 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">4월 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">최근 포스트</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/08/29/machine-learning-3/">Machine Learning(ML) - 손실 줄이기</a>
          </li>
        
          <li>
            <a href="/2018/08/27/machine-learning-2/">Machine Learning(ML) - ML로 전환하기</a>
          </li>
        
          <li>
            <a href="/2018/08/20/machine-learning-1/">Machine Learning(ML) - ML 문제로 표현하기(용어 정리)</a>
          </li>
        
          <li>
            <a href="/2018/08/15/new-django-project/">새로운 장고 프로젝트</a>
          </li>
        
          <li>
            <a href="/2018/08/11/machine-learning-week-0/">Machine Learning(ML) 첫걸음</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 gnidoc327<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
    <div id="footer-count">
      <div id="view-count">
        조회수 : <span id="busuanzi_value_site_pv"></span>
      </div>
      <div id="visitor-count">
        총 방문자 : <span id="busuanzi_value_site_uv"></span>
      </div>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    
<script>
  var disqus_shortname = 'https-gnidoc327-github-io';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>
